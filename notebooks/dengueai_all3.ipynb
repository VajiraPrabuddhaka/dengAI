{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three model types, several dataset versions, total_cases IS THE ONLY FEATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import statsmodels as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "import theano \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import initializers, regularizers\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, GRU, Embedding, Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "%matplotlib inline\n",
    "import myutil_all as myutil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "_ = importlib.reload(myutil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data and do preliminary preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfx_train = myutil.get_indexed_dataset('data/dengue_features_train.csv')\n",
    "dfy_train = myutil.get_indexed_dataset('data/dengue_labels_train.csv')\n",
    "dfx_test = myutil.get_indexed_dataset('data/dengue_features_test.csv')\n",
    "# combine training features with training labels for data exploration later on\n",
    "dftrain = myutil.set_index(pd.merge(dfx_train, dfy_train))\n",
    "# Will stack the train and test datasets to treat all NaN values together\n",
    "# Need to add bogus total_cases column to test dataset so the files can be easily concatenated\n",
    "# update total_cases = -1 to easily identify the records for later split data to original partitions\n",
    "dfx_test['total_cases'] = -1\n",
    "dfall = myutil.set_index(pd.concat((dftrain, dfx_test), axis=0))\n",
    "dfall.sort_index(axis=0, inplace=True)\n",
    "# drop unecessary columns and save column names\n",
    "delcols = ['year','week_start_date','reanalysis_sat_precip_amt_mm','reanalysis_specific_humidity_g_per_kg']\n",
    "dfall.drop(delcols, axis=1, inplace=True)\n",
    "cols = dfall.columns\n",
    "# remove NaNs\n",
    "dfall = myutil.set_nan_to_week_mean(dfall.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encode city and weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(676, 72)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split dataset and hot encode weekof year\n",
    "dfall_copy = dfall.copy()\n",
    "dfall_iq = dfall_copy[dfall_copy['city'] == 'iq']\n",
    "dfall_sj = dfall_copy[dfall_copy['city'] == 'sj']\n",
    "enc = OneHotEncoder(categorical_features=np.array([0]))\n",
    "dset = dict()\n",
    "dset['iq'] = enc.fit_transform(dfall_iq.iloc[:,1:].values).toarray()\n",
    "dset['sj'] = enc.fit_transform(dfall_sj.iloc[:,1:].values).toarray()\n",
    "dset['iq'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create several versions of the datasets (ADD total cases as ONLY feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for each city, create version of datasets with 1 to 16 shifts (3 months)\n",
    "for city in dset.keys():\n",
    "    datashift = dict()\n",
    "    for shift_no in range(1,17):\n",
    "        # total cases is THE ONLY FEATURE\n",
    "        datashift[shift_no] = myutil.shift(np.hstack((dset[city][:,-1:],dset[city][:,-1:])), shift_no)\n",
    "    dset[city] = datashift\n",
    "\n",
    "# for each city, each shift, create version of the dataset different scaling\n",
    "for city in dset.keys():\n",
    "    for shift_no in dset[city].keys():\n",
    "        vers = dict()\n",
    "        # save original as 'raw'\n",
    "        vers['raw'] = np.hstack((dset[city][shift_no][:,:-1], dset[city][shift_no][:,-1:]))\n",
    "        # save scaled with minmax in range [0,1] as 'minmax1'\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        vers['minmax1'] = np.hstack((scaler.fit_transform(dset[city][shift_no][:,:-1]), dset[city][shift_no][:,-1:]))\n",
    "        # save scaled with minmax in range [0,1] as 'minmax1'\n",
    "        # isolate features, so scaling will only affect features\n",
    "        scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "        vers['minmax2'] = np.hstack((scaler.fit_transform(dset[city][shift_no][:,:-1]), dset[city][shift_no][:,-1:]))\n",
    "        dset[city][shift_no] = vers\n",
    "        \n",
    "# for each city, each shift, each version, create X_train, y_train, and X_test partitions\n",
    "dataset = dict()\n",
    "for city in dset.keys():\n",
    "    for shift_no in dset[city].keys():\n",
    "        for vers in dset[city][shift_no].keys():\n",
    "            npdata = dset[city][shift_no][vers]\n",
    "            partition = dict()\n",
    "            partition['X_train'] = npdata[npdata[:,-1]>0][:,:-1]\n",
    "            partition['y_train'] = npdata[npdata[:,-1]>0][:,-1:]\n",
    "            partition['X_test']  = npdata[npdata[:,-1]<0][:,:-1]\n",
    "            id = city + '_' + str(shift_no) + '_' + vers\n",
    "            dataset[id] = partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for key in dataset.keys():\n",
    "#    print(key[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result for iq\n",
      "\tBest dataset: iq_15_raw\n",
      "\tBest model  : BayesianRidge\n",
      "\t\tMAE train : 4.14\n",
      "\t\tMAE valid : 4.70\n",
      "\t\tVariance  : 0.50\n",
      "Best result for sj\n",
      "\tBest dataset: sj_11_minmax1\n",
      "\tBest model  : Lasso\n",
      "\t\tMAE train : 8.67\n",
      "\t\tMAE valid : 7.68\n",
      "\t\tVariance  : 0.90\n"
     ]
    }
   ],
   "source": [
    "best_score = dict()\n",
    "best_score['iq'] = 0 \n",
    "best_score['sj'] = 0 \n",
    "best_result = dict()\n",
    "for id in dataset.keys():\n",
    "    \n",
    "    myscore = dict()\n",
    "    X_train_, X_valid_, y_train_, y_valid_ = train_test_split(dataset[id]['X_train'], dataset[id]['y_train'],\\\n",
    "                                                              test_size=.33, random_state=42)\n",
    "    # Create linear regression object\n",
    "    for i in range(0, 6):\n",
    "        if i==0: \n",
    "            key = 'LinearRegression'\n",
    "            regr = linear_model.LinearRegression()\n",
    "        if i==1:\n",
    "            key = 'Ridge'\n",
    "            regr = linear_model.Ridge(alpha = .5)\n",
    "        if i==2:\n",
    "            key = 'RidgeCV'  \n",
    "            regr = linear_model.RidgeCV(alphas=[0.1, 1.0, 10.0])\n",
    "        if i==3:\n",
    "            key = 'Lasso'\n",
    "            regr = linear_model.Lasso(alpha = .1)\n",
    "        if i==4:\n",
    "            key = 'LassoLars'\n",
    "            regr = linear_model.LassoLars(alpha = .1)\n",
    "        if i==5:\n",
    "            key = 'BayesianRidge'  \n",
    "            regr = linear_model.BayesianRidge()\n",
    "\n",
    "        # Train the model using the training sets\n",
    "        regr.fit(X_train_, y_train_.ravel())\n",
    "\n",
    "        y_hat = regr.predict(X_train_)\n",
    "        y_hat[ y_hat < 0] = 0\n",
    "        y_hat = np.around(y_hat).astype('int')\n",
    "        y_pred = regr.predict(X_valid_)\n",
    "        y_pred[ y_pred < 0] = 0\n",
    "        y_pred = np.around(y_pred).astype('int')\n",
    "\n",
    "        # scores are training mae, validation mae, variance\n",
    "        mae_train = mean_absolute_error(y_train_, y_hat)\n",
    "        mae_valid = mean_absolute_error(y_valid_, y_pred)\n",
    "        r2        = r2_score(y_valid_, y_pred)\n",
    "\n",
    "        if abs(r2) < 1:\n",
    "            this_score = abs(r2/mae_valid)\n",
    "        else: \n",
    "            this_score = 0\n",
    "            \n",
    "        if id[:2] == 'iq':\n",
    "            if this_score > best_score['iq']:\n",
    "                best_score['iq'] = this_score\n",
    "                best_result['iq'] = (regr, id, key, mae_train, mae_valid, r2)\n",
    "        else:\n",
    "            if this_score > best_score['sj']:\n",
    "                best_score['sj'] = this_score\n",
    "                best_result['sj'] = (regr, id, key, mae_train, mae_valid, r2)\n",
    "\n",
    "for city in best_result.keys():\n",
    "    print('Best result for {}'.format(city))\n",
    "    print('\\tBest dataset: {}'.format(best_result[city][1]))\n",
    "    print('\\tBest model  : {}'.format(best_result[city][2]))\n",
    "    print('\\t\\tMAE train : %.2f' % best_result[city][3])\n",
    "    print('\\t\\tMAE valid : %.2f' % best_result[city][4])\n",
    "    print('\\t\\tVariance  : %.2f' % best_result[city][5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decisition tree regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result for iq\n",
      "\tBest dataset: iq_11_minmax2\n",
      "\t\tMAE train : 2.16\n",
      "\t\tMAE valid : 4.20\n",
      "\t\tVariance  : 0.48\n",
      "Feature Importances:\n",
      "[ 0.03152522  0.0511803   0.02637617  0.02672976  0.03925776  0.02938238\n",
      "  0.02539808  0.0390092   0.07366031  0.18001311  0.47746772]\n",
      "Best result for sj\n",
      "\tBest dataset: sj_10_raw\n",
      "\t\tMAE train : 5.44\n",
      "\t\tMAE valid : 8.29\n",
      "\t\tVariance  : 0.91\n",
      "Feature Importances:\n",
      "[ 0.0071397   0.00747151  0.00490085  0.00370157  0.00451026  0.00721144\n",
      "  0.01204337  0.01929248  0.07837265  0.85535617]\n"
     ]
    }
   ],
   "source": [
    "best_score = dict()\n",
    "best_score['iq'] = 0 \n",
    "best_score['sj'] = 0 \n",
    "best_result = dict()\n",
    "for id in dataset.keys():\n",
    "        \n",
    "    myscore = dict()\n",
    "    X_train_, X_valid_, y_train_, y_valid_ = train_test_split(dataset[id]['X_train'], dataset[id]['y_train'],\\\n",
    "                                                              test_size=.33, random_state=42)\n",
    "        \n",
    "    #RandomForestRegressor(n_estimators=10, criterion=’mse’, max_depth=None, min_samples_split=2, \n",
    "    #                      min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=’auto’, \n",
    "    #                      max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, \n",
    "    #                      bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, \n",
    "    #                      warm_start=False)\n",
    "    \n",
    "    #regr = RandomForestRegressor(n_estimators=30, max_depth=max_depth, criterion='mse', random_state=0,\\\n",
    "    #                            min_samples_leaf=1)\n",
    "    \n",
    "    #AdaBoostRegressor(base_estimator=None, n_estimators=150, learning_rate=1.0, loss=’linear’, random_state=None)\n",
    "    \n",
    "    regr = AdaBoostRegressor(RandomForestRegressor(max_depth=6), n_estimators=200, learning_rate=0.01, \\\n",
    "                             loss='exponential', random_state=42)\n",
    "    \n",
    "    regr.fit(X_train_, y_train_.ravel())\n",
    "\n",
    "    y_hat = regr.predict(X_train_)\n",
    "    y_hat[ y_hat < 0] = 0\n",
    "    y_hat = np.around(y_hat).astype('int')\n",
    "    y_pred = regr.predict(X_valid_)\n",
    "    y_pred[ y_pred < 0] = 0\n",
    "    y_pred = np.around(y_pred).astype('int')\n",
    "\n",
    "    # scores are training mae, validation mae, variance\n",
    "    mae_train = mean_absolute_error(y_train_, y_hat)\n",
    "    mae_valid = mean_absolute_error(y_valid_, y_pred)\n",
    "    r2        = r2_score(y_valid_, y_pred)\n",
    "\n",
    "    this_score = abs(r2/mae_valid)\n",
    "    if id[:2] == 'iq':\n",
    "        if this_score > best_score['iq']:\n",
    "            best_score['iq'] = this_score\n",
    "            best_result['iq'] = (regr, id, mae_train, mae_valid, r2)\n",
    "    else:\n",
    "        if this_score > best_score['sj']:\n",
    "            best_score['sj'] = this_score\n",
    "            best_result['sj'] = (regr, id, mae_train, mae_valid, r2)\n",
    "    \n",
    "    #plt.scatter(y_valid, y_pred)\n",
    "    \n",
    "for city in best_result.keys():\n",
    "    print('Best result for {}'.format(city))\n",
    "    print('\\tBest dataset: {}'.format(best_result[city][1]))\n",
    "    #print('\\tBest model  : {}'.format(best_result[city][2]))\n",
    "    print('\\t\\tMAE train : %.2f' % best_result[city][2])\n",
    "    print('\\t\\tMAE valid : %.2f' % best_result[city][3])\n",
    "    print('\\t\\tVariance  : %.2f' % best_result[city][4])\n",
    "    print('Feature Importances:')\n",
    "    print(best_result[city][0].feature_importances_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: iq_1_raw / Train Loss: 5.5922876965831705 / Valid Loss 7.077066026415143 / R2: -0.07733943973712587\n",
      "Database: iq_1_minmax1 / Train Loss: 5.790062341891544 / Valid Loss 7.30391754082271 / R2: -0.0826460246220646\n",
      "Database: iq_1_minmax2 / Train Loss: 5.8795867453158746 / Valid Loss 7.390355508668082 / R2: -0.1313638974689546\n",
      "Database: iq_2_raw / Train Loss: 5.453301263527131 / Valid Loss 6.8938026564461845 / R2: -0.07415548880616263\n",
      "Database: iq_2_minmax1 / Train Loss: 5.739561765966281 / Valid Loss 7.2969489097595215 / R2: -0.08483713063907161\n",
      "Database: iq_2_minmax2 / Train Loss: 5.782768088327328 / Valid Loss 7.3537451335362025 / R2: -0.08483713063907161\n",
      "Database: iq_3_raw / Train Loss: 5.128101364827492 / Valid Loss 6.507271214893886 / R2: -0.02273296946952974\n",
      "Database: iq_3_minmax1 / Train Loss: 5.775552348351814 / Valid Loss 7.351020581381661 / R2: -0.08483713063907161\n",
      "Database: iq_3_minmax2 / Train Loss: 5.778451652594016 / Valid Loss 7.355647649083819 / R2: -0.08483713063907161\n",
      "Database: iq_4_raw / Train Loss: 5.287590289619607 / Valid Loss 6.766405255453927 / R2: -0.07179320263157685\n",
      "Database: iq_4_minmax1 / Train Loss: 5.784659219459749 / Valid Loss 7.321864560672215 / R2: -0.08483713063907161\n",
      "Database: iq_4_minmax2 / Train Loss: 5.790242369745819 / Valid Loss 7.351530820982797 / R2: -0.08483713063907161\n",
      "Database: iq_5_raw / Train Loss: 5.189054645702872 / Valid Loss 6.574742092405047 / R2: -0.028450386732657318\n",
      "Database: iq_5_minmax1 / Train Loss: 5.78565827389838 / Valid Loss 7.350583696365357 / R2: -0.08483713063907161\n",
      "Database: iq_5_minmax2 / Train Loss: 5.793530801652183 / Valid Loss 7.344125778334481 / R2: -0.08483713063907161\n",
      "Database: iq_6_raw / Train Loss: 5.2402501114657225 / Valid Loss 6.657877462250846 / R2: -0.03290107082970284\n",
      "Database: iq_6_minmax1 / Train Loss: 5.806567974493537 / Valid Loss 7.340108251571655 / R2: -0.08483713063907161\n",
      "Database: iq_6_minmax2 / Train Loss: 5.813631294478832 / Valid Loss 7.320462346076965 / R2: -0.1299602201768093\n",
      "Database: iq_7_raw / Train Loss: 5.512313685786556 / Valid Loss 7.053529923302786 / R2: -0.07706555148500005\n",
      "Database: iq_7_minmax1 / Train Loss: 5.805958516161207 / Valid Loss 7.333565933363778 / R2: -0.08483713063907161\n",
      "Database: iq_7_minmax2 / Train Loss: 5.82102289166249 / Valid Loss 7.332752261843 / R2: -0.1299602201768093\n",
      "Database: iq_8_raw / Train Loss: 5.360680656114095 / Valid Loss 6.875346776417324 / R2: -0.07412125277464687\n",
      "Database: iq_8_minmax1 / Train Loss: 5.763301676427814 / Valid Loss 7.3082391602652415 / R2: -0.08483713063907161\n",
      "Database: iq_8_minmax2 / Train Loss: 5.7822354142095005 / Valid Loss 7.349797490664891 / R2: -0.08483713063907161\n",
      "Database: iq_9_raw / Train Loss: 5.2877774129451165 / Valid Loss 6.752557774952479 / R2: -0.04115195442499475\n",
      "Database: iq_9_minmax1 / Train Loss: 5.795760728943516 / Valid Loss 7.339180762427194 / R2: -0.08483713063907161\n",
      "Database: iq_9_minmax2 / Train Loss: 5.815061841212528 / Valid Loss 7.334762620925903 / R2: -0.08483713063907161\n",
      "Database: iq_10_raw / Train Loss: 5.223942244556588 / Valid Loss 6.664634203910827 / R2: -0.04214479933895099\n",
      "Database: iq_10_minmax1 / Train Loss: 5.349401603282337 / Valid Loss 6.790032012122018 / R2: -0.03550300922489846\n",
      "Database: iq_10_minmax2 / Train Loss: 5.798514070645185 / Valid Loss 7.348403338023594 / R2: -0.08483713063907161\n",
      "Database: iq_11_raw / Train Loss: 5.47900323143275 / Valid Loss 6.710662126541138 / R2: -0.07547908120189795\n",
      "Database: iq_11_minmax1 / Train Loss: 5.434758681290562 / Valid Loss 6.556548857688904 / R2: -0.029330764339473125\n",
      "Database: iq_11_minmax2 / Train Loss: 5.925526710786584 / Valid Loss 7.115671614238194 / R2: -0.1287729439010854\n",
      "Database: iq_12_raw / Train Loss: 5.273126647244915 / Valid Loss 6.522468723569598 / R2: -0.0270977812654849\n",
      "Database: iq_12_minmax1 / Train Loss: 5.434924469398526 / Valid Loss 6.564718188558306 / R2: -0.02944241349317256\n",
      "Database: iq_12_minmax2 / Train Loss: 5.927518730871248 / Valid Loss 7.121714881488255 / R2: -0.08217803042386285\n",
      "Database: iq_13_raw / Train Loss: 5.311371876999683 / Valid Loss 6.599568925585065 / R2: -0.05180946061762204\n",
      "Database: iq_13_minmax1 / Train Loss: 5.393482854425275 / Valid Loss 6.5042811870574955 / R2: -0.028586436648143865\n",
      "Database: iq_13_minmax2 / Train Loss: 5.9247684739925 / Valid Loss 7.117369283948626 / R2: -0.08217803042386285\n",
      "Database: iq_14_raw / Train Loss: 5.336076894834269 / Valid Loss 6.620736914021628 / R2: -0.03844877855825879\n",
      "Database: iq_14_minmax1 / Train Loss: 5.562973489188474 / Valid Loss 6.725199777739388 / R2: -0.04179825316924113\n",
      "Database: iq_14_minmax2 / Train Loss: 5.917856405143603 / Valid Loss 7.119683415549142 / R2: -0.08217803042386285\n",
      "Database: iq_15_raw / Train Loss: 5.37314146525447 / Valid Loss 6.548688091550555 / R2: -0.04775287469987677\n",
      "Database: iq_15_minmax1 / Train Loss: 5.469553688810908 / Valid Loss 6.614728205544608 / R2: -0.03152653102889502\n",
      "Database: iq_15_minmax2 / Train Loss: 5.91632654094022 / Valid Loss 7.120547764641898 / R2: -0.08217803042386285\n",
      "Database: iq_16_raw / Train Loss: 5.638020698060381 / Valid Loss 6.300602889060974 / R2: -0.06971424107601765\n",
      "Database: iq_16_minmax1 / Train Loss: 5.637764218005728 / Valid Loss 6.404512711933681 / R2: -0.02923446184325096\n",
      "Database: iq_16_minmax2 / Train Loss: 6.07458610399395 / Valid Loss 6.825628914151873 / R2: -0.0759039258930354\n",
      "Database: sj_1_raw / Train Loss: 25.074004811612983 / Valid Loss 25.461092818867076 / R2: -0.1287448810220153\n",
      "Database: sj_1_minmax1 / Train Loss: 25.245450342830456 / Valid Loss 25.69466950676658 / R2: -0.146114568897741\n",
      "Database: sj_1_minmax2 / Train Loss: 25.332683973480762 / Valid Loss 25.80601441395747 / R2: -0.15154134710057132\n",
      "Database: sj_2_raw / Train Loss: 24.83951712802746 / Valid Loss 26.397372935416257 / R2: -0.15513273183510212\n",
      "Database: sj_2_minmax1 / Train Loss: 25.039062193844522 / Valid Loss 26.698317897436286 / R2: -0.15620523679510345\n",
      "Database: sj_2_minmax2 / Train Loss: 25.06857408183727 / Valid Loss 26.724841509269194 / R2: -0.17183299289213894\n",
      "Database: sj_3_raw / Train Loss: 22.96306992113782 / Valid Loss 22.720995264643566 / R2: -0.09202549161131657\n",
      "Database: sj_3_minmax1 / Train Loss: 25.576414048480068 / Valid Loss 25.33506087759807 / R2: -0.1498262927274303\n",
      "Database: sj_3_minmax2 / Train Loss: 25.61716383753099 / Valid Loss 25.371948489148764 / R2: -0.1498262927274303\n",
      "Database: sj_4_raw / Train Loss: 23.88178331802049 / Valid Loss 23.63836446258843 / R2: -0.11475187157088729\n",
      "Database: sj_4_minmax1 / Train Loss: 25.502577188894175 / Valid Loss 25.61080838492328 / R2: -0.13743661366738325\n",
      "Database: sj_4_minmax2 / Train Loss: 25.565418383157578 / Valid Loss 25.65364280352763 / R2: -0.13743661366738325\n",
      "Database: sj_5_raw / Train Loss: 24.021520709837883 / Valid Loss 22.278256043889165 / R2: -0.1026369268806615\n",
      "Database: sj_5_minmax1 / Train Loss: 26.10208123586412 / Valid Loss 24.40354369980058 / R2: -0.14453241619751322\n",
      "Database: sj_5_minmax2 / Train Loss: 26.24711569265467 / Valid Loss 24.507375430437474 / R2: -0.16066171962337683\n",
      "Database: sj_6_raw / Train Loss: 23.311187038113992 / Valid Loss 23.268387306749432 / R2: -0.10500813495625194\n",
      "Database: sj_6_minmax1 / Train Loss: 25.704352072746524 / Valid Loss 25.61768696354885 / R2: -0.17811239517215083\n",
      "Database: sj_6_minmax2 / Train Loss: 25.671838583484774 / Valid Loss 25.595043643627292 / R2: -0.16119358657199578\n",
      "Database: sj_7_raw / Train Loss: 23.24449509141518 / Valid Loss 23.985783520866843 / R2: -0.13124091571753893\n",
      "Database: sj_7_minmax1 / Train Loss: 25.39923086305042 / Valid Loss 26.309673343608583 / R2: -0.19547180741665993\n",
      "Database: sj_7_minmax2 / Train Loss: 25.410690266019117 / Valid Loss 26.32267118591109 / R2: -0.19547180741665993\n",
      "Database: sj_8_raw / Train Loss: 23.86231543212792 / Valid Loss 23.89195152032571 / R2: -0.1372366115496666\n",
      "Database: sj_8_minmax1 / Train Loss: 25.55521507293997 / Valid Loss 25.880823271391822 / R2: -0.16417229369574193\n",
      "Database: sj_8_minmax2 / Train Loss: 25.589614157915502 / Valid Loss 25.903617329675644 / R2: -0.16417229369574193\n",
      "Database: sj_9_raw / Train Loss: 25.869493232961613 / Valid Loss 25.384784107520932 / R2: -0.1818115604569175\n",
      "Database: sj_9_minmax1 / Train Loss: 25.85170183366942 / Valid Loss 25.369260775456663 / R2: -0.1821880802373006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: sj_9_minmax2 / Train Loss: 25.963162391316928 / Valid Loss 25.46884144642314 / R2: -0.20163298374523886\n",
      "Database: sj_10_raw / Train Loss: 25.3336467549712 / Valid Loss 22.51793090007344 / R2: -0.12179645418769636\n",
      "Database: sj_10_minmax1 / Train Loss: 25.678228877545177 / Valid Loss 22.373768922149157 / R2: -0.13014558736725546\n",
      "Database: sj_10_minmax2 / Train Loss: 26.768891210880618 / Valid Loss 23.548234945828796 / R2: -0.16462007153007407\n",
      "Database: sj_11_raw / Train Loss: 25.430917750687808 / Valid Loss 22.254188728959935 / R2: -0.12469426405478012\n",
      "Database: sj_11_minmax1 / Train Loss: 25.00796951776192 / Valid Loss 21.443104747094605 / R2: -0.10077824355022713\n",
      "Database: sj_11_minmax2 / Train Loss: 26.871306604852165 / Valid Loss 23.29785362670296 / R2: -0.16798893276027616\n",
      "Database: sj_12_raw / Train Loss: 25.080382989598558 / Valid Loss 23.46153009565253 / R2: -0.13175187117157905\n",
      "Database: sj_12_minmax1 / Train Loss: 24.901044210830293 / Valid Loss 23.065206762991455 / R2: -0.1239682012930381\n",
      "Database: sj_12_minmax2 / Train Loss: 26.323000590522568 / Valid Loss 24.42218884982561 / R2: -0.1692294969754864\n",
      "Database: sj_13_raw / Train Loss: 24.78319598872487 / Valid Loss 24.45441095138851 / R2: -0.13030293756142197\n",
      "Database: sj_13_minmax1 / Train Loss: 24.52876432155206 / Valid Loss 23.819687005720642 / R2: -0.10878517470755655\n",
      "Database: sj_13_minmax2 / Train Loss: 25.90483965524813 / Valid Loss 25.34302133321762 / R2: -0.14708702993024692\n",
      "Database: sj_14_raw / Train Loss: 24.486686218075636 / Valid Loss 25.01995063536238 / R2: -0.1460885524138682\n",
      "Database: sj_14_minmax1 / Train Loss: 24.313684052568142 / Valid Loss 24.562991642715907 / R2: -0.13840729528827356\n",
      "Database: sj_14_minmax2 / Train Loss: 25.64712448430255 / Valid Loss 25.909340952882673 / R2: -0.16036338477750545\n",
      "Database: sj_15_raw / Train Loss: 24.520873238287066 / Valid Loss 24.71772313511411 / R2: -0.12645446450605236\n",
      "Database: sj_15_minmax1 / Train Loss: 24.506702218071258 / Valid Loss 24.024274511305805 / R2: -0.1293657206190555\n",
      "Database: sj_15_minmax2 / Train Loss: 25.847701088225026 / Valid Loss 25.55604596972072 / R2: -0.15129629304462333\n",
      "Database: sj_16_raw / Train Loss: 23.529782285892555 / Valid Loss 26.817384729290954 / R2: -0.12594239575829413\n",
      "Database: sj_16_minmax1 / Train Loss: 23.231980911864735 / Valid Loss 25.859647421947013 / R2: -0.11283940155150951\n",
      "Database: sj_16_minmax2 / Train Loss: 24.655907025733935 / Valid Loss 27.810206403826722 / R2: -0.14756751503755483\n",
      "Best result for iq\n",
      "Best dataset: iq_11_minmax2\n",
      "\t\tFinal loss train: 5.925526710786584\n",
      "\t\tFinal loss valid: 7.115671614238194\n",
      "\t\tVariance score: -0.13\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsuRujDFh6P8DFwubpjFdH1QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ccef05cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result for sj\n",
      "Best dataset: sj_7_minmax1\n",
      "\t\tFinal loss train: 25.39923086305042\n",
      "\t\tFinal loss valid: 26.309673343608583\n",
      "\t\tVariance score: -0.20\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ccefe00b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_score = dict()\n",
    "best_score['iq'] = 0 \n",
    "best_score['sj'] = 0 \n",
    "best_result = dict()\n",
    "for id in dataset.keys():\n",
    "        \n",
    "    myscore = dict()\n",
    "    X_train_, X_valid_, y_train_, y_valid_ = train_test_split(dataset[id]['X_train'], dataset[id]['y_train'],\\\n",
    "                                                              test_size=.33, random_state=42)\n",
    "    \n",
    "    X_train_ = X_train_.reshape(X_train_.shape[0], int(id[3:4]), int(X_train_.shape[1]/int(id[3:4])))\n",
    "    X_valid_ = X_valid_.reshape(X_valid_.shape[0], int(id[3:4]), int(X_valid_.shape[1]/int(id[3:4])))\n",
    "    \n",
    "    # build graph\n",
    "    regr = Sequential()\n",
    "    \n",
    "    #keras.layers.LSTM(units, activation='tanh', recurrent_activation='hard_sigmoid', \n",
    "    #              use_bias=True, kernel_initializer='glorot_uniform', \n",
    "    #              recurrent_initializer='orthogonal', bias_initializer='zeros', \n",
    "    #              unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, \n",
    "    #              bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, \n",
    "    #              recurrent_constraint=None, bias_constraint=None, dropout=0.0, \n",
    "    #              recurrent_dropout=0.0, implementation=1, return_sequences=False, \n",
    "    #              return_state=False, go_backwards=False, stateful=False, unroll=False)\n",
    "\n",
    "    regr.add(GRU(X_train_.shape[2], input_shape=(X_train_.shape[1], X_train_.shape[2]),\\\n",
    "                  implementation=2, return_sequences=True))\n",
    "    regr.add(GRU(5))\n",
    "    regr.add(Dense(1, kernel_regularizer=regularizers.l2(0.01), activation='linear'))\n",
    "    regr.compile(loss='mae', optimizer='rmsprop')  # 'adam'\n",
    "    \n",
    "    # fit net\n",
    "    history = regr.fit(X_train_, y_train_, epochs=20, batch_size=4,\\\n",
    "                       validation_data=(X_valid_, y_valid_), verbose=0, shuffle=False)\n",
    "    \n",
    "    y_hat = regr.predict(X_train_)\n",
    "    y_hat[ y_hat < 0] = 0\n",
    "    y_hat = np.around(y_hat).astype('int')\n",
    "    y_pred = regr.predict(X_valid_)\n",
    "    y_pred[ y_pred < 0] = 0\n",
    "    y_pred = np.around(y_pred).astype('int')\n",
    "    \n",
    "    loss_train = history.history['loss'][-1]\n",
    "    loss_valid = history.history['val_loss'][-1]\n",
    "    r2 = r2_score(y_valid_, y_pred)\n",
    "    \n",
    "    print('Database: {} / Train Loss: {} / Valid Loss {} / R2: {}'.format(id, loss_train, loss_valid, r2))\n",
    "\n",
    "    if loss_valid > loss_train:\n",
    "        this_score = abs(r2/loss_valid)\n",
    "        #this_score = loss_valid\n",
    "    else:\n",
    "        this_score = 0\n",
    "    \n",
    "    if id[:2] == 'iq':\n",
    "        if this_score > best_score['iq']:\n",
    "            best_score['iq'] = this_score\n",
    "            best_result['iq'] = (history.history, id, loss_train, loss_valid, r2)\n",
    "    else:\n",
    "        if this_score > best_score['sj']:\n",
    "            best_score['sj'] = this_score\n",
    "            best_result['sj'] = (history.history, id, loss_train, loss_valid, r2)\n",
    "        \n",
    "for city in best_result.keys():\n",
    "    print('Best result for {}'.format(city))\n",
    "    print('Best dataset: {}'.format(best_result[city][1]))\n",
    "    print('\\t\\tFinal loss train: {}'.format(best_result[city][2]))\n",
    "    print('\\t\\tFinal loss valid: {}'.format(best_result[city][3]))\n",
    "    print('\\t\\tVariance score: %.2f' % best_result[city][4])\n",
    "    plt.plot(best_result[city][0]['loss'], label='train')\n",
    "    plt.plot(best_result[city][0]['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
